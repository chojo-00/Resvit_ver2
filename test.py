import os
import numpy as np
import nibabel as nib  # NIfTI ë³€í™˜ì„ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
from options.test_options import TestOptions
from data import CreateDataLoader
from models import create_model
import re
import pydicom

def parse_filename(filepath):
    """
    íŒŒì¼ ê²½ë¡œì—ì„œ í™˜ì IDì™€ ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œ
    
    ì…ë ¥ ì˜ˆì‹œ:
    - /train/70keV/PE001/PE001_0001.dcm
    - /test/80keV/PE275/PE275_0280.dcm
    
    ì¶œë ¥: ('PE001', '0001', '70keV')
    """
    # íŒŒì¼ëª… ì¶”ì¶œ
    basename = os.path.basename(filepath)  # PE001_0001.dcm
    
    # í™•ì¥ì ì œê±°
    name_without_ext = os.path.splitext(basename)[0]  # PE001_0001
    
    # íŒ¨í„´: PE{í™˜ìë²ˆí˜¸}_{ìŠ¬ë¼ì´ìŠ¤ë²ˆí˜¸}
    pattern = r'(PE\d+)_(\d+)'
    match = re.match(pattern, name_without_ext)
    
    if match:
        patient_id = match.group(1)    # PE001
        slice_num = match.group(2)     # 0001
    else:
        # í´ë°±: íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ ì‹œë„
        patient_id = "Unknown"
        slice_match = re.search(r'(\d+)', name_without_ext)
        slice_num = slice_match.group(1) if slice_match else '0000'
    
    # ê²½ë¡œì—ì„œ keV ì •ë³´ ì¶”ì¶œ
    source_kev = 'unknownkeV'
    path_parts = filepath.split(os.sep)
    for part in path_parts:
        if 'keV' in part:
            # "70keV", "80keV" ë“±ì˜ í˜•ì‹
            kev_match = re.search(r'(\d+)\s*keV', part, re.IGNORECASE)
            if kev_match:
                source_kev = f"{kev_match.group(1)}keV"
            else:
                source_kev = part
            break
    
    return patient_id, slice_num, source_kev


def tensor2array(image_tensor, min_hu=-1024.0, max_hu=3071.0):
    """
    Tensorë¥¼ numpy arrayë¡œ ë³€í™˜í•˜ê³  ì›ë³¸ CT HU ê°’ìœ¼ë¡œ ë³µì›
    
    ì •ê·œí™” ë³µì› ê³¼ì •:
    1. ëª¨ë¸ ì¶œë ¥: [-1, 1] (Tanh ì¶œë ¥)
    2. [0, 1]ë¡œ ë³€í™˜: (tensor + 1) / 2
    3. ì›ë³¸ HU ë²”ìœ„ë¡œ ë³µì›: normalized * (max_hu - min_hu) + min_hu
    
    Args:
        image_tensor: torch tensor [C, H, W] with values in [-1, 1]
        min_hu: ìµœì†Œ HU ê°’ (ì „ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•œ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨)
        max_hu: ìµœëŒ€ HU ê°’ (ì „ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•œ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨)
    
    Returns:
        numpy array [H, W] with original CT HU values
    """
    # Tensor â†’ Numpy
    image_numpy = image_tensor[0].cpu().float().numpy()
    
    if image_numpy.shape[0] == 1:
        # Single channel
        image_numpy = image_numpy[0]  # [H, W]
    else:
        # Multi-channelì¸ ê²½ìš° ì²« ë²ˆì§¸ ì±„ë„ë§Œ ì‚¬ìš©
        image_numpy = image_numpy[0]
    
    # Step 1: [-1, 1] â†’ [0, 1]
    image_numpy = (image_numpy + 1.0) / 2.0
    
    # Step 2: [0, 1] â†’ [min_hu, max_hu]
    image_numpy = image_numpy * (max_hu - min_hu) + min_hu
    
    return image_numpy


def save_dicom(dcm_path, hu_numpy_array, save_path):
    """
    Original DICOM í—¤ë”ë¥¼ ì½ì–´ì™€ì„œ ìƒì„±ëœ ì´ë¯¸ì§€(HU)ë¥¼ ë®ì–´ì“°ê³  ì €ì¥
    Args:
        dcm_path: ì›ë³¸ DICOM íŒŒì¼ ê²½ë¡œ (í—¤ë” ì •ë³´ìš©)
        hu_numpy_array: ëª¨ë¸ì´ ìƒì„±í•œ HU ê°’ì„ ê°€ì§„ Numpy ë°°ì—´ (fake_B)
        save_path: ì €ì¥í•  ê²½ë¡œ (.dcm)
    """
    # ì›ë³¸ DICOM ì½ê¸°
    try:
        dcm = pydicom.dcmread(dcm_path, force=True)
    except Exception as e:
        print(f"Failed to read reference DICOM: {dcm_path}, Error: {e}")
        return

    # Rescale Intercept/Slope ì ìš©í•˜ì—¬ Raw Pixel ê°’ìœ¼ë¡œ ì—­ë³€í™˜
    # HU = PixelValue * Slope + Intercept
    # PixelValue = (HU - Intercept) / Slope
    intercept = dcm.RescaleIntercept
    slope = dcm.RescaleSlope
    
    # ì›ë³¸ ë°°ì—´ ë³´ì¡´ì„ ìœ„í•´ ë³µì‚¬
    predict_img = hu_numpy_array.copy()
    
    predict_img -= np.float32(intercept)
    if slope != 1:
        predict_img = predict_img.astype(np.float32) / slope
    
    # ì •ìˆ˜í˜• ë³€í™˜ (ë°˜ì˜¬ë¦¼)
    predict_img = np.round(predict_img).astype(np.int16)

    # DICOM íƒœê·¸ ì—…ë°ì´íŠ¸
    dcm.file_meta.TransferSyntaxUID = pydicom.uid.ExplicitVRLittleEndian
    dcm.PixelData = predict_img.tobytes()
    dcm.Rows, dcm.Columns = predict_img.shape

    # í”½ì…€ ê°’ ë²”ìœ„ ì—…ë°ì´íŠ¸
    dcm.SmallestImagePixelValue = int(predict_img.min())
    dcm.LargestImagePixelValue = int(predict_img.max())
    
    # Pixel Representation ë“±ì„ ì—…ë°ì´íŠ¸ (Unsigned/Signed ì²˜ë¦¬)
    # CTëŠ” ë³´í†µ Signed Short (SS)ë¥¼ ì“°ì§€ë§Œ, ì½”ë“œ ì˜ˆì‹œëŒ€ë¡œ US(Unsigned Short)ë¡œ ê°•ì œí•  ê²½ìš°:
    dcm[0x0028,0x0106].VR = 'SS' 
    dcm[0x0028,0x0107].VR = 'SS'
    
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± í›„ ì €ì¥
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    dcm.save_as(save_path)


def save_ct_image_npy_only(image_array, npy_dir, filename_base):
    """
    CT ì´ë¯¸ì§€ë¥¼ numpy í˜•ì‹ìœ¼ë¡œë§Œ ì €ì¥
    
    Args:
        image_array: numpy array [H, W] with HU values
        npy_dir: numpy ì €ì¥ ë””ë ‰í† ë¦¬
        filename_base: íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
    
    Returns:
        npy_path
    """
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(npy_dir, exist_ok=True)
    
    # Numpy ì €ì¥ (.npy)
    npy_path = os.path.join(npy_dir, f"{filename_base}.npy")
    np.save(npy_path, image_array)
    
    return npy_path


if __name__ == '__main__':
    opt = TestOptions().parse()
    opt.nThreads = 1
    opt.batchSize = 1
    opt.serial_batches = True
    opt.no_flip = True

    # Source keV ë¦¬ìŠ¤íŠ¸
    src_list = opt.src.split(',')
    
    # CT HU ê°’ ë²”ìœ„ ì„¤ì •
    # ì£¼ì˜: ì „ì²˜ë¦¬ ì‹œ ì‚¬ìš©í•œ ê°’ê³¼ ë™ì¼í•´ì•¼ í•¨!
    MIN_HU = -1024.0
    MAX_HU = 3071.0
    
    print(f"{'='*80}")
    print(f"âš™ï¸  CT Value Range Settings")
    print(f"{'='*80}")
    print(f"Min HU: {MIN_HU}")
    print(f"Max HU: {MAX_HU}")
    print(f"Range: {MAX_HU - MIN_HU}")
    print(f"\nğŸ’¡ These values should match the preprocessing settings!")
    print(f"   Check data/dect_dataset.py _CT_preprocess function")
    print(f"{'='*80}\n")
    
    data_loader = CreateDataLoader(opt)
    dataset = data_loader.load_data()
    model = create_model(opt)
    
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ (base)
    results_base = os.path.join(opt.results_dir, opt.name, 
                                f'{opt.phase}_{opt.which_epoch}')
    
    # npy,dcm base ë””ë ‰í† ë¦¬
    npy_base = os.path.join(results_base, 'npy')
    dcm_base = os.path.join(results_base, 'dcm') 

    print(f"{'='*80}")
    print(f"ğŸ§ª Testing {opt.name} (Numpy Output Only)")
    print(f"{'='*80}")
    print(f"Source keV: {src_list}")
    print(f"Target keV: {opt.trg}")
    print(f"Total samples to test: {min(opt.how_many, len(dataset))}")
    print(f"Results directory: {results_base}")
    print(f"  - Numpy:  {npy_base}")
    print(f"{'='*80}\n")
    
    # í†µê³„
    stats = {kev: {'patients': set(), 'slices': 0} for kev in src_list}
    
    # Test loop
    for i, data in enumerate(dataset):
        if i >= opt.how_many:
            break
        
        model.set_input(data)
        model.test()
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        img_paths = model.get_image_paths()
        img_path = img_paths[0] if isinstance(img_paths, list) else img_paths
        
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        patient_id, slice_num, source_kev = parse_filename(img_path)
        
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if (i + 1) % 10 == 0 or i == 0:
            print(f'[{i+1:04d}/{min(opt.how_many, len(dataset))}] '
                  f'{source_kev} â†’ 70keV | {patient_id} | slice {slice_num}')
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        if source_kev in stats:
            stats[source_kev]['patients'].add(patient_id)
            stats[source_kev]['slices'] += 1
        
        # íŒŒì¼ëª…: PE{í™˜ìë²ˆí˜¸}_{ìŠ¬ë¼ì´ìŠ¤ë²ˆí˜¸}
        filename_base = f"{patient_id}_{slice_num}"
        
        # ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° ë° ë³€í™˜ (HU ê°’ìœ¼ë¡œ ë³µì›)
        real_A = tensor2array(model.real_A.data, MIN_HU, MAX_HU)
        real_B = tensor2array(model.real_B.data, MIN_HU, MAX_HU)
        fake_B = tensor2array(model.fake_B.data, MIN_HU, MAX_HU)
        
        # ì €ì¥ ê²½ë¡œ ì„¤ì • (ì˜ˆ: results/../dcm/80keV/PE001/fake_B/PE001_0001.dcm)
        dcm_kev_dir = os.path.join(dcm_base, source_kev)
        dcm_patient_dir = os.path.join(dcm_kev_dir, patient_id, 'fake_B')
        save_filename = f"{patient_id}_{slice_num}.dcm"
        save_path = os.path.join(dcm_patient_dir, save_filename)
        # ì €ì¥ (DICOM)
        save_dicom(img_path, fake_B, save_path)

        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        # npy ê²½ë¡œ
        npy_kev_dir = os.path.join(npy_base, source_kev)
        npy_patient_dir = os.path.join(npy_kev_dir, patient_id)
        npy_real_A_dir = os.path.join(npy_patient_dir, 'real_A')
        npy_real_B_dir = os.path.join(npy_patient_dir, 'real_B')
        npy_fake_B_dir = os.path.join(npy_patient_dir, 'fake_B')
        
        # ì €ì¥ (npy)
        save_ct_image_npy_only(real_A, npy_real_A_dir, filename_base)
        save_ct_image_npy_only(real_B, npy_real_B_dir, filename_base)
        save_ct_image_npy_only(fake_B, npy_fake_B_dir, filename_base)
    
    # ìµœì¢… í†µê³„
    print(f"\n{'='*80}")
    print(f"âœ… Testing Complete (Numpy Only)!")
    print(f"{'='*80}")
    print(f"\nğŸ“Š Statistics by Source keV:")
    print(f"{'-'*80}")
    print(f"{'keV':<12} {'Patients':<15} {'Slices':<10}")
    print(f"{'-'*80}")
    
    total_slices = 0
    all_patients = set()
    
    for kev in src_list:
        if kev in stats:
            num_patients = len(stats[kev]['patients'])
            num_slices = stats[kev]['slices']
            total_slices += num_slices
            all_patients.update(stats[kev]['patients'])
            print(f"{kev:<12} {num_patients:<15} {num_slices:<10}")
    
    print(f"{'-'*80}")
    print(f"{'Total':<12} {len(all_patients):<15} {total_slices:<10}")
    print(f"\nğŸ“ Results saved to: {npy_base}")
    print(f"\nğŸ’¡ To load:")
    print(f"   img = np.load('PE001_0001.npy')  # Shape: [H, W], dtype: float32")