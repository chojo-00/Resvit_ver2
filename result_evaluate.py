import os
import glob
import numpy as np
import pydicom
import pandas as pd
import math
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# =========================================================
# [ÏÑ§Ï†ï] Í≤ΩÎ°ú Î∞è ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï
# =========================================================

# 1. ÏÉùÏÑ±Îêú(Fake) DICOM ÌååÏùºÏù¥ ÏûàÎäî ÏµúÏÉÅÏúÑ Í≤ΩÎ°ú
FAKE_B_ROOT = "/workspace/bc_cho/2_Code/ResViT/results/ct_contrast_total_train/test_latest/dcm"

# 2. Ï†ïÎãµ(Real, GT) DICOM ÌååÏùº Í≤ΩÎ°ú (70keV ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Í≥≥)
REAL_B_ROOT = "/workspace/bc_cho/2_Code/data/CCY_PE_DECT/journal_data/internal/test/70keV"

# 3. Í≤∞Í≥º ÏóëÏÖÄ ÌååÏùº Ï†ÄÏû• Ïù¥Î¶Ñ
OUTPUT_EXCEL_NAME = "evaluation_total_metrics_result.xlsx"

# 4. CT HU Î≤îÏúÑ (PSNR/SSIM Í≥ÑÏÇ∞Ïö©)
MIN_HU = -1024.0
MAX_HU = 3071.0
DATA_RANGE = MAX_HU - MIN_HU  # 4095.0

# =========================================================

def read_dicom_to_hu(path):
    """DICOM ÌååÏùºÏùÑ ÏùΩÏñ¥ HU(Hounsfield Unit) Í∞íÏùò Numpy Î∞∞Ïó¥Î°ú Î≥ÄÌôò"""
    try:
        dcm = pydicom.dcmread(path, force=True)
        img = dcm.pixel_array.astype(np.float32)
        
        # Rescale Slope/Intercept Ï†ÅÏö©
        slope = getattr(dcm, 'RescaleSlope', 1)
        intercept = getattr(dcm, 'RescaleIntercept', 0)
        img = img * slope + intercept
        return img
    except Exception as e:
        print(f"Error reading {path}: {e}")
        return None

def calculate_rmse(img1, img2):
    """Calculate Root Mean Square Error"""
    mse = np.mean((img1 - img2) ** 2)
    return math.sqrt(mse)

def evaluate():
    print(f"üîç Searching for generated DICOM files in: {FAKE_B_ROOT}")
    
    # 1. Î™®Îì† DICOM ÌååÏùº ÌÉêÏÉâ
    all_files = glob.glob(os.path.join(FAKE_B_ROOT, "**", "*.dcm"), recursive=True)
    fake_files = [f for f in all_files if "fake_B" in f]

    if not fake_files:
        print("‚ùå 'fake_B' Ìè¥Îçî ÎÇ¥Ïùò DICOM ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        print("   Í≤ΩÎ°úÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî:", FAKE_B_ROOT)
        return

    print(f"   Total generated files found: {len(fake_files)}")
    print(f"üìä Starting evaluation with Metrics (PSNR, SSIM, MAE, RMSE)...")
    
    results_data = []
    missing_gt_count = 0

    for idx, fake_path in enumerate(fake_files):
        # -----------------------------------------------------------
        # Í≤ΩÎ°ú ÌååÏã± Î∞è Ï†ïÎ≥¥ Ï∂îÏ∂ú
        # -----------------------------------------------------------
        filename = os.path.basename(fake_path)
        filename_no_ext = os.path.splitext(filename)[0]
        
        # Patient ID Ï∂îÏ∂ú (ÌååÏùºÎ™Ö Í∑úÏπô: PE275_0001 -> PE275)
        patient_id = filename_no_ext.split('_')[0]
        
        # Source keV Ï∂îÏ∂ú
        path_parts = fake_path.split(os.sep)
        source_kev = "Unknown"
        for part in reversed(path_parts):
            if "keV" in part and part != "70keV":
                source_kev = part
                break
        
        # -----------------------------------------------------------
        # Ï†ïÎãµ(GT) ÌååÏùº Îß§Ïπ≠
        # -----------------------------------------------------------
        gt_name_1 = f"{filename_no_ext}_70keV.dcm"
        gt_name_2 = f"{filename_no_ext}_70 keV.dcm"
        gt_name_3 = filename

        real_path = None
        candidate_paths = [
            os.path.join(REAL_B_ROOT, patient_id, gt_name_1),
            os.path.join(REAL_B_ROOT, patient_id, gt_name_2),
            os.path.join(REAL_B_ROOT, patient_id, gt_name_3)
        ]

        for p_cand in candidate_paths:
            if os.path.exists(p_cand):
                real_path = p_cand
                break
        
        if real_path is None:
            missing_gt_count += 1
            if missing_gt_count <= 5:
                print(f"‚ö†Ô∏è GT File missing for: {filename} (Patient: {patient_id})")
            continue

        # -----------------------------------------------------------
        # Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è ÌèâÍ∞Ä
        # -----------------------------------------------------------
        fake_img = read_dicom_to_hu(fake_path)
        real_img = read_dicom_to_hu(real_path)

        if fake_img is None or real_img is None:
            continue
        if fake_img.shape != real_img.shape:
            # shapeÏù¥ Îã§Î•¥Î©¥ skip
            continue

        # ÏßÄÌëú Í≥ÑÏÇ∞
        val_psnr = psnr(real_img, fake_img, data_range=DATA_RANGE)
        val_ssim = ssim(real_img, fake_img, data_range=DATA_RANGE)
        val_mae = np.mean(np.abs(real_img - fake_img))
        val_rmse = calculate_rmse(real_img, fake_img)

        # Í≤∞Í≥º Î¶¨Ïä§Ìä∏Ïóê Ï∂îÍ∞Ä
        results_data.append({
            "Source_keV": source_kev,
            "Patient_ID": patient_id,
            "Filename": filename,
            "PSNR": val_psnr,
            "SSIM": val_ssim,
            "MAE": val_mae,
            "RMSE": val_rmse,
            "Fake_Path": fake_path,
            "Real_Path": real_path
        })
        
        if (idx + 1) % 100 == 0:
            print(f"   Processed {idx + 1}/{len(fake_files)} files...")

    # =========================================================
    # [Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Î∞è ÏóëÏÖÄ Ï†ÄÏû•]
    # =========================================================
    if len(results_data) > 0:
        print("\nüìà Calculating Statistics...")
        
        # 1. Í∏∞Î≥∏ DataFrame ÏÉùÏÑ± (Detail Data)
        df_detail = pd.DataFrame(results_data)
        
        # --- [Sheet 2] Detail_All_Files: ÏÜåÏàòÏ†ê 3ÏûêÎ¶¨ Ï†ïÎ¶¨ ---
        metric_cols = ["PSNR", "SSIM", "MAE", "RMSE"]
        df_detail_rounded = df_detail.copy()
        df_detail_rounded[metric_cols] = df_detail_rounded[metric_cols].round(3)

        # --- [Sheet 3] Patient_Average: ÌôòÏûêÎ≥Ñ ÌèâÍ∑† ---
        # (Source_keV, Patient_ID) Í∏∞Ï§ÄÏúºÎ°ú Í∑∏Î£πÌôîÌïòÏó¨ ÌèâÍ∑† Í≥ÑÏÇ∞
        df_patient = df_detail.groupby(["Source_keV", "Patient_ID"])[metric_cols].mean().reset_index()
        # ÏÜåÏàòÏ†ê 3ÏûêÎ¶¨ Î∞òÏò¨Î¶º
        df_patient = df_patient.round(3)

        # --- [Sheet 1] Summary: keVÎ≥Ñ Mean & Std ---
        # ÌèâÍ∑†(mean)Í≥º ÌëúÏ§ÄÌé∏Ï∞®(std) ÏßëÍ≥Ñ
        summary_agg = df_detail.groupby("Source_keV")[metric_cols].agg(['mean', 'std'])
        
        # Ïª¨Îüº Ïù¥Î¶Ñ ÌèâÌÉÑÌôî (Ïòà: ('PSNR', 'mean') -> 'PSNR_Mean')
        summary_agg.columns = [f"{col}_{stat.capitalize()}" for col, stat in summary_agg.columns]
        summary_agg = summary_agg.reset_index()
        
        # Îç∞Ïù¥ÌÑ∞ Í∞úÏàò(Count) Ï∂îÍ∞Ä
        summary_agg["Count"] = df_detail.groupby("Source_keV")["Filename"].count().values

        # Ï†ÑÏ≤¥ ÌèâÍ∑†(Total Average) Ìñâ Í≥ÑÏÇ∞
        total_stats = {}
        total_stats["Source_keV"] = "TOTAL_AVERAGE"
        total_stats["Count"] = len(df_detail)
        for col in metric_cols:
            total_stats[f"{col}_Mean"] = df_detail[col].mean()
            total_stats[f"{col}_Std"] = df_detail[col].std()
            
        total_df = pd.DataFrame([total_stats])
        
        # Summary ÌÖåÏù¥Î∏î Ìï©ÏπòÍ∏∞
        df_summary = pd.concat([summary_agg, total_df], ignore_index=True)
        
        # ÏÜåÏàòÏ†ê 3ÏûêÎ¶¨ Î∞òÏò¨Î¶º
        df_summary = df_summary.round(3)
        
        # Ïª¨Îüº ÏàúÏÑú Î≥¥Í∏∞ Ï¢ãÍ≤å Ï†ïÎ†¨ (Source_keV, Count, Í∑∏ Îí§Î°ú ÏßÄÌëúÎì§)
        cols = ['Source_keV', 'Count'] + [c for c in df_summary.columns if c not in ['Source_keV', 'Count']]
        df_summary = df_summary[cols]

        # -----------------------------------------------------
        # ÏΩòÏÜî Ï∂úÎ†• (Summary)
        # -----------------------------------------------------
        print("-" * 80)
        print("   [Summary by keV (Mean / Std)]")
        print("-" * 80)
        print(df_summary.to_string(index=False))
        print("-" * 80)

        # -----------------------------------------------------
        # ÏóëÏÖÄ Ï†ÄÏû•
        # -----------------------------------------------------
        with pd.ExcelWriter(OUTPUT_EXCEL_NAME, engine='openpyxl') as writer:
            # Sheet 1: Summary
            df_summary.to_excel(writer, sheet_name='Summary', index=False)
            
            # Sheet 2: Detail (Original)
            df_detail_rounded.to_excel(writer, sheet_name='Detail_All_Files', index=False)
            
            # Sheet 3: Patient Average (New!)
            df_patient.to_excel(writer, sheet_name='Patient_Average', index=False)
            
        print(f"\n‚úÖ Excel saved successfully: {os.path.abspath(OUTPUT_EXCEL_NAME)}")
        if missing_gt_count > 0:
            print(f"‚ö†Ô∏è Warning: {missing_gt_count} files were skipped because GT file was not found.")
        
    else:
        print("\n‚ùå No data processed. Please check file paths.")

if __name__ == "__main__":
    evaluate()